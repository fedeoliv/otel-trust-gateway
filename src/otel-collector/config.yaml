receivers:
  otlp:
    protocols:
      http:
        endpoint: 0.0.0.0:4318
      grpc:
        endpoint: 0.0.0.0:4317

processors:
  # Memory Limiter Processor
  # Prevents the collector from running out of memory by monitoring and limiting memory usage.
  # - Checks memory usage every 1 second
  # - Sets a soft limit at 80% (~205 MiB) where collector starts refusing new data
  # - Sets a hard limit at 256 MiB where collector forces garbage collection
  # - Spike limit allows temporary bursts up to 64 MiB above the limit
  # - Protects system from OOM crashes, essential for production
  # - Tuned for mobile app traffic (lower memory footprint)
  memory_limiter:
    check_interval: 1s
    limit_mib: 256
    spike_limit_mib: 64

  # Trust Gateway Processor (Custom)
  # Validates authentication tokens and required headers from mobile applications.
  # - Checks that required headers are present in resource attributes
  # - Validates API keys against a whitelist
  # - Rejects telemetry data if validation fails
  # - Acts as a security gateway before data is exported
  trustgateway:
    # Headers that must be present in the resource attributes
    required_headers:
      - "X-App-Token"
      - "X-API-Key"
    # Valid API keys for authentication
    valid_api_keys:
      - "mobile-app-secret-key-123"
      - "mobile-app-secret-key-456"

  # Probabilistic Sampling Processor
  # Samples a percentage of traces to reduce volume sent to Application Insights
  # - sampling_percentage: 10 means keep 10% of traces, drop 90%
  # - Uses trace ID for consistent sampling decisions across distributed traces
  # - All spans in a sampled trace are kept together
  # - Adjust percentage based on your volume needs (1-100)
  # Example: 10% of 1M spans/day = 100K spans/day sent to App Insights
  probabilistic_sampler:
    sampling_percentage: 10

  # Batch Processor (for full data pipeline)
  # Groups telemetry data into batches before sending to exporters for better performance.
  # - Sends batch after 5 seconds even if not full (lower latency for mobile apps)
  # - Sends batch when it reaches 100 spans/metrics/logs
  # - Reduces network calls: 1000 spans = ~10 requests instead of 1000
  # - Improves throughput and reduces CPU usage
  # - Tuned for mobile app traffic (smaller batches, faster send)
  batch:
    timeout: 5s
    send_batch_size: 100

  # Batch Processor (for sampled data pipeline to Azure Monitor)
  # Smaller batches for sampled data since volume is reduced
  batch/sampled:
    timeout: 10s
    send_batch_size: 50

exporters:
  debug:
    verbosity: detailed

  # Azure Monitor Exporter
  # Sends telemetry data to Azure Application Insights
  # Resiliency Configuration:
  # - sending_queue: Buffers data in memory (or disk) when Azure is unavailable
  # - maxbatchsize: Controls batch size (default 1024 items per request)
  # - maxbatchinterval: Maximum time to wait before sending (default 10s)
  azuremonitor:
    connection_string: "${env:APPLICATIONINSIGHTS_CONNECTION_STRING}"
    maxbatchsize: 1024
    maxbatchinterval: 10s
    spaneventsenabled: true  # Export span events to Application Insights
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 5000  # Buffer up to 5000 batches in memory
      # For k8s cluster with persistent storage:
      # storage: file_storage/azuremonitor
      # shutdown_timeout: 5s 

  # Example OTLP exporter to send to external system
  # otlp:
  #   endpoint: "external-otel-collector:4317"
  #   tls:
  #     insecure: true

extensions:
  health_check:
    endpoint: 0.0.0.0:13133

service:
  extensions: [health_check]

  telemetry:
    resource:
      service.name: "otelcol-custom"
      service.namespace: "telemetry-infrastructure"
      service.version: "0.1.0"
    logs:
      level: debug # Options: debug, info, warn, error

  pipelines:
    # ============================================
    # AZURE MONITOR PIPELINES (Sampled Data)
    # ============================================
    
    # Sampled traces + correlated logs pipeline - sends 10% to Azure Monitor
    # The probabilistic sampler uses trace_id for sampling decisions
    # Logs with the same trace_id will be kept together with their traces
    traces/sampled:
      receivers: [otlp]
      processors: [memory_limiter, trustgateway, probabilistic_sampler, batch/sampled]
      exporters: [azuremonitor]
    
    logs/sampled:
      receivers: [otlp]
      processors: [memory_limiter, trustgateway, probabilistic_sampler, batch/sampled]
      exporters: [azuremonitor]
    
    # Full metrics pipeline - sends 100% of metrics to Azure Monitor (no sampling)
    metrics/full:
      receivers: [otlp]
      processors: [memory_limiter, trustgateway, batch]
      exporters: [azuremonitor]
    
    # ============================================
    # FUTURE EXPORTER PIPELINES (Full Data)
    # ============================================
    # Uncomment these pipelines when you add other exporters
    # These will receive 100% of all telemetry data
    
    # Full traces + logs pipeline - sends 100% to other exporters
    # traces/full:
    #   receivers: [otlp]
    #   processors: [memory_limiter, trustgateway, batch]
    #   exporters: [debug]  # Replace with: otlp, elasticsearch, etc.
    
    # logs/full:
    #   receivers: [otlp]
    #   processors: [memory_limiter, trustgateway, batch]
    #   exporters: [debug]  # Replace with: otlp, elasticsearch, etc.
    
    # Full metrics pipeline - sends 100% of metrics to other exporters
    # metrics/full-export:
    #   receivers: [otlp]
    #   processors: [memory_limiter, trustgateway, batch]
    #   exporters: [debug]  # Replace with: otlp, prometheus, etc.
