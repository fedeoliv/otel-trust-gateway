receivers:
  otlp:
    protocols:
      http:
        endpoint: 0.0.0.0:4318
      grpc:
        endpoint: 0.0.0.0:4317

processors:
  # Memory Limiter Processor
  # Prevents the collector from running out of memory by monitoring and limiting memory usage.
  # - Checks memory usage every 1 second
  # - Sets a soft limit at 80% (~205 MiB) where collector starts refusing new data
  # - Sets a hard limit at 256 MiB where collector forces garbage collection
  # - Spike limit allows temporary bursts up to 64 MiB above the limit
  # - Protects system from OOM crashes, essential for production
  # - Tuned for mobile app traffic (lower memory footprint)
  memory_limiter:
    check_interval: 1s
    limit_mib: 256
    spike_limit_mib: 64

  # Trust Gateway Processor (Custom)
  # Validates authentication tokens and required headers from mobile applications.
  # - Checks that required headers are present in resource attributes
  # - Validates API keys against a whitelist
  # - Rejects telemetry data if validation fails
  # - Acts as a security gateway before data is exported
  trustgateway:
    # Headers that must be present in the resource attributes
    required_headers:
      - "X-App-Token"
      - "X-API-Key"
    # Valid API keys for authentication
    valid_api_keys:
      - "mobile-app-secret-key-123"
      - "mobile-app-secret-key-456"

  # Probabilistic Sampling Processor
  # Samples a percentage of traces to reduce volume sent to Application Insights
  # - sampling_percentage: 10 means keep 10% of traces, drop 90%
  # - Uses trace ID for consistent sampling decisions across distributed traces
  # - All spans in a sampled trace are kept together
  # - Adjust percentage based on your volume needs (1-100)
  # Example: 10% of 1M spans/day = 100K spans/day sent to App Insights
  probabilistic_sampler:
    sampling_percentage: 10

  # Batch Processor (for full data pipeline)
  # Groups telemetry data into batches before sending to exporters for better performance.
  # - Sends batch after 5 seconds even if not full (lower latency for mobile apps)
  # - Sends batch when it reaches 100 spans/metrics/logs
  # - Reduces network calls: 1000 spans = ~10 requests instead of 1000
  # - Improves throughput and reduces CPU usage
  # - Tuned for mobile app traffic (smaller batches, faster send)
  batch:
    timeout: 5s
    send_batch_size: 100

  # Batch Processor (for sampled data pipeline to Azure Monitor)
  # Smaller batches for sampled data since volume is reduced
  batch/sampled:
    timeout: 10s
    send_batch_size: 50

exporters:
  debug:
    verbosity: detailed

  # Azure Monitor Exporter
  # Sends telemetry data to Azure Application Insights
  # Resiliency Configuration:
  # - sending_queue: Buffers data in memory (or disk) when Azure is unavailable
  # - maxbatchsize: Controls batch size (default 1024 items per request)
  # - maxbatchinterval: Maximum time to wait before sending (default 10s)
  azuremonitor:
    connection_string: "${env:APPLICATIONINSIGHTS_CONNECTION_STRING}"
    maxbatchsize: 1024
    maxbatchinterval: 10s
    spaneventsenabled: true # Export span events to Application Insights

  # Azure Blob Exporter (Custom with DefaultAzureCredential support)
  # Exports full telemetry batches to Azure Data Lake Storage
  # Uses DefaultAzureCredential for automatic credential discovery
  # - Tries environment variables first (AZURE_TENANT_ID, AZURE_CLIENT_ID, AZURE_CLIENT_SECRET)
  # - Falls back to Workload Identity (AKS), Managed Identity (VM), Azure CLI, or Azure PowerShell
  # - No explicit credentials needed in config - follows Azure SDK best practices
  azureblob:
    url: "${env:AZURE_STORAGE_ACCOUNT_URL}"
    auth:
      type: default_credentials # Use DefaultAzureCredential for automatic credential discovery
    container:
      metrics: "metrics"
      logs: "logs"
      traces: "traces"
    blob_name_format:
      metrics_format: "2006/01/02/metrics_15_04_05.json"
      logs_format: "2006/01/02/logs_15_04_05.json"
      traces_format: "2006/01/02/traces_15_04_05.json"

      serial_num_range: 10000
    format: "json" # Options: "json" or "proto"
    append_blob:
      enabled: false
      separator: "\n"
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 120s

  # Example OTLP exporter to send to external system
  # otlp:
  #   endpoint: "external-otel-collector:4317"
  #   tls:
  #     insecure: true

extensions:
  health_check:
    endpoint: 0.0.0.0:13133

service:
  extensions: [health_check]

  telemetry:
    resource:
      service.name: "otelcol-custom"
      service.namespace: "telemetry-infrastructure"
      service.version: "0.1.0"
    logs:
      level: debug # Options: debug, info, warn, error

  pipelines:
    # ============================================
    # AZURE MONITOR PIPELINES (Sampled Data)
    # ============================================

    # Sampled traces + correlated logs pipeline - sends 10% to Azure Monitor
    # The probabilistic sampler uses trace_id for sampling decisions
    # Logs with the same trace_id will be kept together with their traces
    traces/sampled:
      receivers: [otlp]
      processors:
        [memory_limiter, trustgateway, probabilistic_sampler, batch/sampled]
      exporters: [azuremonitor]

    logs/sampled:
      receivers: [otlp]
      processors:
        [memory_limiter, trustgateway, probabilistic_sampler, batch/sampled]
      exporters: [azuremonitor]

    # Full metrics pipeline - sends 100% of metrics to Azure Monitor (no sampling)
    metrics/full:
      receivers: [otlp]
      processors: [memory_limiter, trustgateway, batch]
      exporters: [azuremonitor]

    # ============================================
    # AZURE BLOB STORAGE PIPELINES (Full Data)
    # ============================================
    # These pipelines send 100% of all telemetry data to Azure Blob Storage
    # Useful for long-term storage, data lake analytics, or backup

    # Full traces pipeline - sends 100% to Azure Blob Storage
    traces/full:
      receivers: [otlp]
      processors: [memory_limiter, trustgateway, batch]
      exporters: [azureblob]

    # Full logs pipeline - sends 100% to Azure Blob Storage
    logs/full:
      receivers: [otlp]
      processors: [memory_limiter, trustgateway, batch]
      exporters: [azureblob]

    # Full metrics pipeline - sends 100% of metrics to Azure Blob Storage
    metrics/full-export:
      receivers: [otlp]
      processors: [memory_limiter, trustgateway, batch]
      exporters: [azureblob]
